{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score, f1_score, recall_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and test set\n",
    "ds = pd.read_csv('data/alldata.csv')\n",
    "print(ds.shape)\n",
    "pd.set_option('display.max_columns',None)\n",
    "print(ds['Whether the critically ill'].value_counts())\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ds.iloc[:, :-1]\n",
    "y = ds.iloc[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)\n",
    "X_train.insert(X_train.shape[1], y_train.name, y_train)\n",
    "X_test.insert(X_test.shape[1], y_test.name, y_test)\n",
    "X_train.to_csv('data/train.csv', index=False)\n",
    "X_test.to_csv('data/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7 machine learning model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(x, y, model_class, model_paras, kfold, random_seed, outfile):\n",
    "    skf = StratifiedKFold(n_splits=kfold, shuffle=True, random_state=random_seed)\n",
    "    outdict = {'acc':[], 'auc':[], 'recall_0':[], 'recall_1':[], 'f1':[]}\n",
    "    for i, (train_idx, test_idx) in enumerate(skf.split(x, y)):\n",
    "        print(f'**** Fold {i + 1} ****')\n",
    "        train_x = x[train_idx, :]\n",
    "        train_y = y[train_idx]\n",
    "        test_x = x[test_idx, :]\n",
    "        test_y = y[test_idx]\n",
    "        model = model_class(**model_paras)\n",
    "        model.fit(train_x, train_y)\n",
    "        y_pred = model.predict(test_x)\n",
    "\n",
    "        acc = accuracy_score(test_y, y_pred)\n",
    "        recall = recall_score(test_y, y_pred, labels=None, pos_label=1, average=None, sample_weight=None, zero_division='warn')\n",
    "        f1 = f1_score(test_y, y_pred, average='macro')\n",
    "        auc = roc_auc_score(test_y, y_pred, multi_class='ovr')\n",
    "\n",
    "        outdict['acc'].append(acc)\n",
    "        outdict['auc'].append(auc)\n",
    "        outdict['recall_0'].append(recall[0])\n",
    "        outdict['recall_1'].append(recall[1])\n",
    "        outdict['f1'].append(f1)\n",
    "\n",
    "        print('acc   ', acc)\n",
    "        print('recall', recall)\n",
    "        print('f1    ', f1)\n",
    "        print('auc   ', auc)\n",
    "        print()\n",
    "    outdf = pd.DataFrame(outdict)\n",
    "    outdf.to_csv(outfile, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv').to_numpy()\n",
    "x = df[:, 1:-1]    # remove idx column and label column\n",
    "y = df[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "model_class = LogisticRegression\n",
    "model_paras = {'random_state':0, 'max_iter':200}\n",
    "outfile = 'output_ML/lr.cross_validation.csv'\n",
    "cross_validation(x, y,\n",
    "                 model_class, \n",
    "                 model_paras,\n",
    "                 kfold=5,\n",
    "                 random_seed=1,\n",
    "                 outfile=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "model_class = KNeighborsClassifier\n",
    "model_paras = {'n_neighbors':4, 'algorithm':'auto', 'metric':'minkowski'}\n",
    "outfile = 'output_ML/knn.cross_validation.csv'\n",
    "cross_validation(x, y,\n",
    "                 model_class, \n",
    "                 model_paras,\n",
    "                 kfold=5,\n",
    "                 random_seed=1,\n",
    "                 outfile=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "model_class = SVC\n",
    "model_paras = {'kernel':'linear', 'degree':2, 'random_state':0, 'probability':True}\n",
    "outfile = 'output_ML/svm.cross_validation.csv'\n",
    "cross_validation(x, y,\n",
    "                 model_class, \n",
    "                 model_paras,\n",
    "                 kfold=5,\n",
    "                 random_seed=1,\n",
    "                 outfile=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel SVM\n",
    "model_class = SVC\n",
    "model_paras = {'kernel':'rbf', 'degree':2, 'random_state':0, 'probability':True}\n",
    "outfile = 'output_ML/kernel_svm.cross_validation.csv'\n",
    "cross_validation(x, y,\n",
    "                 model_class, \n",
    "                 model_paras,\n",
    "                 kfold=5,\n",
    "                 random_seed=1,\n",
    "                 outfile=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Classifier\n",
    "model_class = DecisionTreeClassifier\n",
    "model_paras = {'criterion':'entropy', 'random_state':0}\n",
    "outfile = 'output_ML/dt.cross_validation.csv'\n",
    "cross_validation(x, y,\n",
    "                 model_class, \n",
    "                 model_paras,\n",
    "                 kfold=5,\n",
    "                 random_seed=1,\n",
    "                 outfile=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF\n",
    "model_class = RandomForestClassifier\n",
    "model_paras = {'n_estimators':1000, 'criterion':'entropy', 'random_state':0}\n",
    "outfile = 'output_ML/rf.cross_validation.csv'\n",
    "cross_validation(x, y,\n",
    "                 model_class, \n",
    "                 model_paras,\n",
    "                 kfold=5,\n",
    "                 random_seed=1,\n",
    "                 outfile=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "model_class = XGBClassifier\n",
    "model_paras = {'n_estimators':500, 'learning_rate':0.01, 'max_depth':3}\n",
    "outfile = 'output_ML/xgb.cross_validation.csv'\n",
    "cross_validation(x, y,\n",
    "                 model_class, \n",
    "                 model_paras,\n",
    "                 kfold=5,\n",
    "                 random_seed=1,\n",
    "                 outfile=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANN model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import metrics, initializers\n",
    "from keras.layers import Dense, Dropout, Activation, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(in_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 64, activation='relu', input_shape = [in_dim]))\n",
    "    model.add(Dense(units = 128, activation='relu'))\n",
    "    model.add(Dense(units = 64, activation='relu'))\n",
    "    model.add(Dense(units = 1, activation='sigmoid'))\n",
    "      \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-fold cross validation\n",
    "traindf = pd.read_csv('data/train.csv').to_numpy().astype('float32')\n",
    "x = traindf[:, 1:-1]  # remove idx column and label column\n",
    "y = traindf[:, -1].reshape(-1)\n",
    "\n",
    "in_dim = x.shape[1]\n",
    "lr = 0.0001\n",
    "early_stopping = 10\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "\n",
    "for i, (train_idx, test_idx) in enumerate(skf.split(x, y)):\n",
    "    print(f'**** Fold {i + 1} ****')\n",
    "    model = build_model(in_dim)\n",
    "    optimizers = tf.keras.optimizers.Adam(learning_rate= lr)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = optimizers, metrics = ['accuracy', metrics.AUC(name='AUC'), metrics.Precision(name='presicion'), metrics.Recall(name='recall'), metrics.F1Score(threshold=0.5, name='f1score', average='macro')])\n",
    "    early = EarlyStopping(monitor = 'accuracy', mode = 'max', patience = early_stopping)  # loss 连续10个循环不下降则停止训练\n",
    "    train_x = x[train_idx, :]\n",
    "    train_y = y[train_idx]\n",
    "    test_x = x[test_idx, :]\n",
    "    test_y = y[test_idx]\n",
    "    results = model.fit(train_x, \n",
    "                        train_y, \n",
    "                        epochs = 600,\n",
    "                        batch_size = 16, \n",
    "                        validation_data = (test_x, test_y), \n",
    "                        shuffle=True, \n",
    "                        verbose=0,\n",
    "                        callbacks = [early])\n",
    "    outdf = pd.DataFrame(results.history).iloc[:-early_stopping, :]\n",
    "    outfile = f'output/5fold_cross_validation.fold_{i+1}.csv'\n",
    "    outdf.to_csv(outfile, index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation results\n",
    "df_list = []\n",
    "for i in range(1,6):\n",
    "    df = pd.read_csv(f'output/5fold_cross_validation.fold_{i}.csv')\n",
    "    df = df.iloc[-2:-1, :]\n",
    "    df.index = [i]\n",
    "    df_list.append(df)\n",
    "mergedf = pd.concat(df_list)\n",
    "mergedf.to_csv('output/ANN.cross_validation.csv', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on training set and test on testing set\n",
    "traindata = pd.read_csv('data/train.csv').to_numpy().astype('float32')\n",
    "testdata = pd.read_csv('data/test.csv').to_numpy().astype('float32')\n",
    "train_x = traindata[:, 1:-1]\n",
    "train_y = traindata[:, -1]\n",
    "test_x = testdata[:, 1:-1]\n",
    "test_y = testdata[:, -1]\n",
    "\n",
    "in_dim = train_x.shape[1]\n",
    "lr = 0.0001\n",
    "training_epochs = 150\n",
    "model_path = 'model_ckpt/best_model.ckpt'\n",
    "checkpoint = ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True, mode='min', verbose=1, save_weights_only=True)\n",
    "model = build_model(in_dim)\n",
    "optimizers = tf.keras.optimizers.Adam(learning_rate= lr)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = optimizers, metrics = ['accuracy', metrics.AUC(name='AUC'), metrics.Precision(name='presicion'), metrics.Recall(name='recall'), metrics.F1Score(threshold=0.5, name='f1score', average='macro')])\n",
    "results = model.fit(train_x,\n",
    "                    train_y,\n",
    "                    epochs=training_epochs,\n",
    "                    batch_size=64,\n",
    "                    validation_data=(test_x, test_y),\n",
    "                    verbose=0,\n",
    "                    callbacks=[checkpoint]\n",
    "                    )\n",
    "outdf = pd.DataFrame(results.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
